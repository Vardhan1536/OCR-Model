{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "890137aa-a969-44f7-bb99-ab80432b9b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: protobuf 5.28.2\n",
      "Uninstalling protobuf-5.28.2:\n",
      "  Successfully uninstalled protobuf-5.28.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y protobuf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea418227-334f-45e6-974e-3aedb46b5bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20.3\n",
      "  Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
      "Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "Installing collected packages: protobuf\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-status 1.66.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.20.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2ea5870-3a14-4470-bc15-e942764c43c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: grpcio-status 1.66.2\n",
      "Uninstalling grpcio-status-1.66.2:\n",
      "  Successfully uninstalled grpcio-status-1.66.2\n",
      "Collecting grpcio-status==1.48.0\n",
      "  Downloading grpcio_status-1.48.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from grpcio-status==1.48.0) (3.20.3)\n",
      "Requirement already satisfied: grpcio>=1.48.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from grpcio-status==1.48.0) (1.66.2)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.5.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from grpcio-status==1.48.0) (1.65.0)\n",
      "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'grpcio-status' candidate (version 1.48.0 at https://files.pythonhosted.org/packages/ef/a6/0b7fbff7e9994f53a28b65eb5d3aa663424c933fa921abf16e9d3488141f/grpcio_status-1.48.0-py3-none-any.whl (from https://pypi.org/simple/grpcio-status/) (requires-python:>=3.6))\n",
      "Reason for being yanked: Deadlock observed in Apache Beam.\u001b[0m\u001b[33m\n",
      "\u001b[0mDownloading grpcio_status-1.48.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: grpcio-status\n",
      "Successfully installed grpcio-status-1.48.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y grpcio-status\n",
    "!pip install grpcio-status==1.48.0  # Adjust version if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e2881b-6d94-450b-ac74-6a82b1c1debb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c82845e6-b991-4c3f-b542-541837831e92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.generativeai as ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc2c57b4-401d-4b6f-8414-21c70448cf84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_KEY = 'AIzaSyBXCoFS0SbIarbw_WMEgTi92ebJ2PGmZE4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "179b47eb-358e-4c14-8865-c024cf383a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai.configure(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf9697ca-6d6c-4f87-8b69-21c80ef537b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ai.GenerativeModel(\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8207b33-9b12-491c-9f83-dc9ae3e53702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2620743-c9b8-45f2-86bc-e1d16a3d485b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of 2 and 3 is **2.5**. \n",
      "\n",
      "Here's how to calculate it:\n",
      "\n",
      "1. **Add the numbers:** 2 + 3 = 5\n",
      "2. **Divide the sum by the number of values:** 5 / 2 = 2.5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 64,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = ai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  generation_config=generation_config,\n",
    "\n",
    ")\n",
    "\n",
    "chat_session = model.start_chat(\n",
    "  history=[\n",
    "  ]\n",
    ")\n",
    "\n",
    "response = chat_session.send_message(\"average of 2 and 3\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97165baa-6a9b-45e9-a728-3cfb670ff40f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_target_and_stance(tweet_text):\n",
    "    json_response = chat_session.send_message(tweet_text)\n",
    "    print(json_response)\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6dbb36ef-09d7-4129-b125-0d9e13589382",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Hello there! What can I do for you today? \\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 90,\n",
      "        \"candidates_token_count\": 12,\n",
      "        \"total_token_count\": 102\n",
      "      }\n",
      "    }),\n",
      ")\n",
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Bye! Have a great day! \\ud83d\\udc4b \\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 106,\n",
      "        \"candidates_token_count\": 8,\n",
      "        \"total_token_count\": 114\n",
      "      }\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "k =  predict_target_and_stance(\"hello\")\n",
    "p=  predict_target_and_stance(\"bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac95d2e3-9957-4b56-b985-3bd34ed1540e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
